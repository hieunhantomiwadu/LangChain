{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieunhantomiwadu/LangChain/blob/main/LangChain_for_LLM_Application_Development.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Libraries"
      ],
      "metadata": {
        "id": "qCWiVTNjr9Ie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6q4H7-Br5Wq",
        "outputId": "94079566-bb85-42c2-a3c6-071cdae53f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.13.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.11)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.27)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.29 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.22)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.29->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.29->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install python-dotenv\n",
        "!pip install wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries\n"
      ],
      "metadata": {
        "id": "hchxIDVDr97e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.output_parsers import ResponseSchema\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.memory import ConversationBufferWindowMemory\n"
      ],
      "metadata": {
        "id": "wdQXQLo0sDma"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## API KEY and LLM"
      ],
      "metadata": {
        "id": "AkEXqIIts5hD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_API_KEY = \"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\"\n",
        "# first initialize the large language model\n",
        "bot = ChatOpenAI(\n",
        "\ttemperature=0.5,\n",
        "\topenai_api_key= YOUR_API_KEY,\n",
        "\tmodel_name=\"gpt-3.5-turbo-0301\"\n",
        ")"
      ],
      "metadata": {
        "id": "TUwBWKLMtAyK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversation Chat Bot"
      ],
      "metadata": {
        "id": "enX8PUXt7GUb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM chatbot\n"
      ],
      "metadata": {
        "id": "p0aUcbJK-0Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text= \"\"\"\n",
        " Tom là một chú chó nhỏ dễ thương, sống cùng gia đình ở một ngôi nhà nhỏ bên bờ sông. Mỗi ngày, Tom thích chơi đùa với các em bé trong khu phố và khám phá những nơi mới thú vị. Một ngày, khi đang chơi ở công viên, Tom gặp một chú chim nhỏ tên là Pia.\n",
        "Pia kể cho Tom nghe về một hòn đảo xa xôi nơi có nhiều kho báu và kỳ quan độc đáo. Tom rất tò mò và muốn khám phá hòn đảo đó. Anh ta nói lời tạm biệt với gia đình và Pia, bắt đầu cuộc hành trình phiêu lưu của mình. Trên đường đi, Tom gặp gỡ nhiều bạn\n",
        "mới và trải qua nhiều thử thách khác nhau. Anh ta vượt qua rừng rậm, leo qua núi cao và băng qua dòng sông nguy hiểm. Mỗi bước đi, Tom học được nhiều bài học quý giá về tình bạn, sự dũng cảm và lòng kiên nhẫn. Cuối cùng, sau một hành trình mạo hiểm,\n",
        "Tom và Pia đến được hòn đảo legendarily. Họ khám phá ra rất nhiều kho báu và thấy những cảnh đẹp tuyệt vời mà họ chưa từng thấy. Nhưng điều quan trọng nhất là, qua cuộc phiêu lưu này, Tom đã hiểu được giá trị của sự can đảm, lòng trung thành và lòng dũng cảm.\n",
        "Anh ta nhận ra rằng, gia đình và bạn bè mới luôn là những kho báu quý giá nhất trong cuộc sống. Sau khi trở về nhà, Tom chia sẻ những câu chuyện tuyệt vời của mình với gia đình và bạn bè. Anh ta nhớ mãi cuộc phiêu lưu đầy kỳ diệu và hứa rằng sẽ luôn luôn trân\n",
        "trọng mọi khoảnh khắc trong cuộc sống.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "2Gj0BgOP_KQj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 1: translate to english\n",
        "first_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Translate the following review to english:\"\n",
        "    \"\\n\\n{Review}\"\n",
        ")\n",
        "# chain 1: input= Review and output= English_Review\n",
        "chain_one = LLMChain(llm=bot, prompt=first_prompt,\n",
        "                     output_key=\"English_Review\"\n",
        "                    )\n"
      ],
      "metadata": {
        "id": "u3B2X3jxAunW"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Can you summarize the following review in 1 sentence:\"\n",
        "    \"\\n\\n{English_Review}\"\n",
        ")\n",
        "# chain 2: input= English_Review and output= summary\n",
        "chain_two = LLMChain(llm=bot, prompt=second_prompt,\n",
        "                     output_key=\"summary\"\n",
        "                    )"
      ],
      "metadata": {
        "id": "mz7f53fSA11O"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template 3: translate to english\n",
        "third_prompt = ChatPromptTemplate.from_template(\n",
        "    \"What language is the following review:\\n\\n{Review}\"\n",
        ")\n",
        "# chain 3: input= Review and output= language\n",
        "chain_three = LLMChain(llm=bot, prompt=third_prompt,\n",
        "                       output_key=\"language\"\n",
        "                      )\n"
      ],
      "metadata": {
        "id": "rtRYi41dAvPV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# prompt template 4: follow up message\n",
        "fourth_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Write a follow up response to the following \"\n",
        "    \"summary in the specified language:\"\n",
        "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
        ")\n",
        "# chain 4: input= summary, language and output= followup_message\n",
        "chain_four = LLMChain(llm=bot, prompt=fourth_prompt,\n",
        "                      output_key=\"followup_message\"\n",
        "                     )"
      ],
      "metadata": {
        "id": "hG_RQS5uBPoG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overall_chain: input= Review\n",
        "# and output= English_Review,summary, followup_message\n",
        "overall_chain = SequentialChain(\n",
        "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
        "    input_variables=[\"Review\"],\n",
        "    output_variables=[\"English_Review\", \"summary\",\"followup_message\"],\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "mnJ-bpWCBu06"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIiD0m5zByp6",
        "outputId": "b0914e46-e339-4a32-db17-5407d983ae0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Review': '\\n Tom là một chú chó nhỏ dễ thương, sống cùng gia đình ở một ngôi nhà nhỏ bên bờ sông. Mỗi ngày, Tom thích chơi đùa với các em bé trong khu phố và khám phá những nơi mới thú vị. Một ngày, khi đang chơi ở công viên, Tom gặp một chú chim nhỏ tên là Pia.\\nPia kể cho Tom nghe về một hòn đảo xa xôi nơi có nhiều kho báu và kỳ quan độc đáo. Tom rất tò mò và muốn khám phá hòn đảo đó. Anh ta nói lời tạm biệt với gia đình và Pia, bắt đầu cuộc hành trình phiêu lưu của mình. Trên đường đi, Tom gặp gỡ nhiều bạn\\nmới và trải qua nhiều thử thách khác nhau. Anh ta vượt qua rừng rậm, leo qua núi cao và băng qua dòng sông nguy hiểm. Mỗi bước đi, Tom học được nhiều bài học quý giá về tình bạn, sự dũng cảm và lòng kiên nhẫn. Cuối cùng, sau một hành trình mạo hiểm,\\nTom và Pia đến được hòn đảo legendarily. Họ khám phá ra rất nhiều kho báu và thấy những cảnh đẹp tuyệt vời mà họ chưa từng thấy. Nhưng điều quan trọng nhất là, qua cuộc phiêu lưu này, Tom đã hiểu được giá trị của sự can đảm, lòng trung thành và lòng dũng cảm.\\nAnh ta nhận ra rằng, gia đình và bạn bè mới luôn là những kho báu quý giá nhất trong cuộc sống. Sau khi trở về nhà, Tom chia sẻ những câu chuyện tuyệt vời của mình với gia đình và bạn bè. Anh ta nhớ mãi cuộc phiêu lưu đầy kỳ diệu và hứa rằng sẽ luôn luôn trân\\ntrọng mọi khoảnh khắc trong cuộc sống.\\n',\n",
              " 'English_Review': 'Tom is a cute little dog who lives with his family in a small house by the river. Every day, Tom likes to play with the kids in the neighborhood and explore new and exciting places. One day, while playing in the park, Tom meets a little bird named Pia. Pia tells Tom about a faraway island where there are many treasures and unique wonders. Tom is very curious and wants to explore the island. He says goodbye to his family and Pia, and begins his adventure journey. Along the way, Tom meets many new friends and faces various challenges. He crosses through dense forests, climbs high mountains, and crosses dangerous rivers. With each step, Tom learns valuable lessons about friendship, courage, and patience. Finally, after an adventurous journey, Tom and Pia arrive at the legendary island. They discover many treasures and see beautiful sights that they have never seen before. But the most important thing is that through this adventure, Tom understands the value of bravery, loyalty, and courage. He realizes that family and new friends are always the most valuable treasures in life. After returning home, Tom shares his wonderful stories with his family and friends. He will always remember the magical adventure and promises to cherish every moment in life.',\n",
              " 'summary': 'Tom, a curious little dog, embarks on an adventurous journey to a faraway island where he learns valuable lessons about friendship, courage, and the importance of family and new friends.',\n",
              " 'followup_message': 'Tom, một chú chó tò mò, bắt đầu một hành trình phiêu lưu đến một hòn đảo xa xôi, nơi anh học được những bài học quý giá về tình bạn, lòng dũng cảm và sự quan trọng của gia đình và những người bạn mới.\\n\\nChào bạn,\\n\\nTôi rất thích câu chuyện về Tom - chú chó tò mò và hành trình phiêu lưu đến hòn đảo xa xôi. Tôi tin rằng câu chuyện này sẽ mang đến cho các em nhỏ những bài học quý giá về tình bạn, lòng dũng cảm và sự quan trọng của gia đình và những người bạn mới.\\n\\nTôi hy vọng rằng các em sẽ có cơ hội đọc câu chuyện này và học được những bài học quý giá từ Tom và hành trình phiêu lưu của anh ấy.\\n\\nChúc các em đọc sách vui vẻ!\\n\\nTrân trọng,\\n[Your Name]'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MEMORY"
      ],
      "metadata": {
        "id": "K_Xe3psSs2G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "prompt =\"\"\"This will be a conversation between me and you.\n",
        "I will enter a sentence and you will output only 1 answer in the form \"bot: <answer> . I will give you an example:\n",
        "  Me: who are you?\n",
        "  bot : I'm together AI.\".\n",
        "  Me: {input}\n",
        "  \"\"\"\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=bot,\n",
        "    memory=memory,\n",
        "    verbose=True)\n",
        "conversation.predict(input=\"Hi, my name is Nhan\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "p9PCLJF7rs3q",
        "outputId": "21280aa8-737b-4f12-b19d-4d030672222d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, my name is Nhan\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Nhan, it's nice to meet you. My name is AI. How can I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "6X6eKSKZr91f",
        "outputId": "641bf6ff-eef7-456e-a60c-e3f4c9c7226a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi, my name is Nhan\n",
            "AI: Hello Nhan, it's nice to meet you. My name is AI. How can I assist you today?\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Your name is Nhan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##WindowMemory"
      ],
      "metadata": {
        "id": "f2UizIiNs0EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=bot,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")\n",
        "conversation.predict(input=\"Hi, my name is Nhan\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "wrsBUbPDsB3Z",
        "outputId": "c588c8c0-2487-42b8-d80e-68326c6c2cbf"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, my name is Nhan\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello Nhan, it's nice to meet you. My name is AI. How can I assist you today?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is 1+1?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "-MRgr5RGsc31",
        "outputId": "a700d3a8-68a7-4a30-9a96-b7d30d237c6e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi, my name is Nhan\n",
            "AI: Hello Nhan, it's nice to meet you. My name is AI. How can I assist you today?\n",
            "Human: What is 1+1?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The answer to 1+1 is 2.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What is my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "LR_fLf6Qsev1",
        "outputId": "74c20c38-ae06-42f5-a94d-3145c02fd829"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: What is 1+1?\n",
            "AI: The answer to 1+1 is 2.\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I'm sorry, I don't have access to your personal information and therefore don't know your name. Is there anything else I can assist you with?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AGENTS"
      ],
      "metadata": {
        "id": "_YpGg1h3sm2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_openai_functions_agent\n",
        "from langchain.agents import load_tools, initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.python import PythonREPL\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "\n",
        "tools = load_tools([\"llm-math\",\"wikipedia\"], llm=bot)\n",
        "# initialize the math tool\n",
        "agent= initialize_agent(\n",
        "    tools,\n",
        "    bot,\n",
        "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    handle_parsing_errors=True,\n",
        "    verbose = True)\n",
        "\n",
        "agent(\"What is the 25% of 300?\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egxN3GoSsgXd",
        "outputId": "c480d733-48ad-4c63-9558-9ec7b1804eee"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3mQuestion: What is the 25% of 300?\n",
            "Thought: I need a calculator to perform this calculation.\n",
            "Action:\n",
            "```\n",
            "{\n",
            "  \"action\": \"Calculator\",\n",
            "  \"action_input\": \"300*0.25\"\n",
            "}\n",
            "```\n",
            "\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAnswer: 75.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI don't need to do anything else, I have the final answer.\n",
            "Final Answer: 75.0\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What is the 25% of 300?', 'output': '75.0'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NlOU3nYPssWY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}